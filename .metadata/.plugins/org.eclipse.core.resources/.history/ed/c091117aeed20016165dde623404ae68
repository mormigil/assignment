package sparkassign.g2;

import java.io.Serializable;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaPairRDD;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.broadcast.Broadcast;

import com.google.common.base.CharMatcher;
import com.google.common.base.Splitter;

import scala.Tuple2;

/**
 * Hello world!
 *
 */
public class App implements Serializable
{
    /**
	 * 
	 */
	private static final long serialVersionUID = 5949733314738766267L;

	public static void main( String[] args )
    {
    	
    	SparkConf sparkConf = new SparkConf().setAppName("SparkTest").setMaster("local[2]");
        JavaSparkContext spark = new JavaSparkContext(sparkConf);
        
        JavaPairRDD<String, String> blogPosts = spark.wholeTextFiles("/media/removable/SD Card/blogs/thirties");
        JavaRDD<Map<String, Integer>> blogPostWordFreqRDD = blogPosts.map(x -> countWordFrequencies(x._2()));
        
        blogPostWordFreqRDD.cache();
        
        Map<String, Integer> masterWordFreq = 
        		blogPostWordFreqRDD.map(x -> genMasterWordList(x)).reduce((x, y) -> combineMasterWordList(x, y));
        
        int totalWords = masterWordFreq.values().stream().reduce((x,y) -> x+y).get();
        
        Broadcast<Map<String, Integer>> broadcastMasterFreq = spark.broadcast(masterWordFreq);
        
        Broadcast<Integer> broadcastTotalWords = spark.broadcast(totalWords);
        
        //create all pairs of words and flat map them with their frequencies
        
        JavaPairRDD<Tuple2<String, String>, Integer> allPairFreq = blogPostWordFreqRDD
        		.flatMapToPair(x -> allWordPairFrequencies(x).iterator());
        
        allPairFreq = allPairFreq.reduceByKey((x, y) -> x+y);
        
        allPairFreq.map(x -> new Tuple2<Tuple2<String, String>, Double>(x._1(), 
        		calculateSimilarity(x._2(), broadcastMasterFreq.getValue().get(x._1()._1()), 
        				broadcastMasterFreq.getValue().get(x._1()._2()), broadcastTotalWords.getValue())));
        
        spark.close();
    }
	
	public static double calculateSimilarity(int XYFreq, int XFreq, int YFreq, int totalWords){
		double probXY = XYFreq/(totalWords);
		double probX = XFreq/totalWords;
		double probY =  YFreq/totalWords;
		double probNotXY = probY-probXY;
		double probXNotY = probX-probXY;
		double probNotXNotY = 1-probX-probY+probXY;
		double resultSum = 0;
		if(probXY>0)
			resultSum = probXY*Math.log(probXY/(probX*probY));
		if(probXNotY>0)
			resultSum += probXNotY*Math.log(probXNotY/(probX*(1-probY)));
		if(probNotXY>0)
			resultSum += probNotXY*Math.log(probNotXY/((1-probX)*probY));
		if(probNotXNotY>0)
			resultSum += probNotXNotY*Math.log(probNotXNotY/((1-probX)*(1-probY)));
		return resultSum;
		
	}
    
	public static List<Tuple2<Tuple2<String, String>, Integer>> allWordPairFrequencies(Map<String, Integer> singleContextFreq){
		List<Tuple2<Tuple2<String, String>, Integer>> pairList = new ArrayList<Tuple2<Tuple2<String, String>, Integer>>();
		
		for(Entry<String, Integer> wordFreq : singleContextFreq.entrySet()){
			for(Entry<String, Integer> wordFreq2 : singleContextFreq.entrySet()){
				int stringCompare = wordFreq.getKey().compareTo(wordFreq2.getKey());
				if(stringCompare<0){
					pairList.add(new Tuple2<Tuple2<String, String>, Integer>(new Tuple2<String, String>(wordFreq.getKey(), 
							wordFreq2.getKey()), Math.min(wordFreq.getValue(), wordFreq2.getValue())));
				}
			}
		}
		return pairList;
	}
	
    public static Map<String, Integer> 
    	combineMasterWordList(Map<String, Integer> mainList, 
    		Map<String, Integer> otherList){
    	for(Entry<String, Integer> entry : otherList.entrySet()){
    		Integer mainData = mainList.get(entry.getKey());
    		if(mainData==null){
    			mainData = 0;
    		} 
    		mainList.put(entry.getKey(), mainData+entry.getValue());
    	}
    	return mainList;
    }
    
    public static Map<String, Integer> genMasterWordList(Map<String, Integer> singleContextFreq){
    	Map<String, Integer> masterWordList = new HashMap<String, Integer>();
    	for(Entry<String, Integer> entry : singleContextFreq.entrySet()){
    		masterWordList.put(entry.getKey(), entry.getValue());
    	}
    	return masterWordList;
    }
    
    public static Map<String, Integer> countWordFrequencies(String context){
    	Splitter wordSplitter = Splitter.on(' ').trimResults(CharMatcher.JAVA_LETTER.negate()).omitEmptyStrings();
    	
    	Map<String, Integer> wordFreq = new HashMap<String, Integer>();
    	
    	for(String word : wordSplitter.split(context)){
    		Integer curFreq = wordFreq.get(word);
    		if(curFreq==null){
    			curFreq = 0;
    		}
    		wordFreq.put(word, ++curFreq);
    	}
    	
    	return wordFreq;
    }
}
