package sparkassign.g2;

import java.io.Serializable;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.stream.Stream;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaPairRDD;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.broadcast.Broadcast;

import com.google.common.base.CharMatcher;
import com.google.common.base.Splitter;

import scala.Tuple2;

/**
 * Hello world!
 *
 */
public class App implements Serializable
{
    /**
	 * 
	 */
	private static final long serialVersionUID = 5949733314738766267L;

	public static void main( String[] args )
    {
    	
    	SparkConf sparkConf = new SparkConf().setAppName("SparkTest").setMaster("local[2]");
        JavaSparkContext spark = new JavaSparkContext(sparkConf);
        
        JavaPairRDD<String, String> blogPosts = spark.wholeTextFiles("/media/removable/SD Card/blogPosts");
        JavaRDD<Map<String, Integer>> blogPostWordFreqRDD = blogPosts.map(x -> countWordFrequencies(x._2()));
        
        blogPostWordFreqRDD.cache();
        
        Map<String, Integer> masterWordFreq = 
        		blogPostWordFreqRDD.map(x -> genMasterWordList(x)).reduce((x, y) -> combineMasterWordList(x, y));
        
        Broadcast<Map<String, Integer>> broadcastMasterFreq = spark.broadcast(masterWordFreq);
        
        blogPostWordFreqRDD.flatMapToPair(x -> Arrays.asList(new Tuple2<String, String>("", "")));
        
        spark.close();
    }
    
	public static List<Tuple2<Tuple2<String, String>, Integer>> allWordPairFrequencies(Map<String, Integer> singleContextFreq){
		List<Tuple2<Tuple2<String, String>, Integer>> pairList = new ArrayList<Tuple2<Tuple2<String, String>, Integer>>();
		
		for(Entry<String, Integer> wordFreq : singleContextFreq.entrySet()){
			for(Entry<String, Integer> wordFreq2 : singleContextFreq.entrySet()){
				int stringCompare = wordFreq.getKey().compareTo(wordFreq2.getKey());
				if(stringCompare<0){
					pairList.add(new Tuple2<Tuple2<String, String>, Integer>(new Tuple2<String, String>(wordFreq.getKey(), 
							wordFreq2.getKey()), Math.min(wordFreq.getValue(), wordFreq2.getValue())));
				}
			}
		}
		return pairList;
	}
	
    public static Map<String, Integer> 
    	combineMasterWordList(Map<String, Integer> mainList, 
    		Map<String, Integer> otherList){
    	for(Entry<String, Integer> entry : otherList.entrySet()){
    		Integer mainData = mainList.get(entry.getKey());
    		if(mainData==null){
    			mainData = 0;
    		} 
    		mainList.put(entry.getKey(), mainData+entry.getValue());
    	}
    	return mainList;
    }
    
    public static Map<String, Integer> genMasterWordList(Map<String, Integer> singleContextFreq){
    	Map<String, Integer> masterWordList = new HashMap<String, Integer>();
    	for(Entry<String, Integer> entry : singleContextFreq.entrySet()){
    		masterWordList.put(entry.getKey(), entry.getValue());
    	}
    	return masterWordList;
    }
    
    public static Map<String, Integer> countWordFrequencies(String context){
    	Splitter wordSplitter = Splitter.on(' ').trimResults(CharMatcher.JAVA_LETTER.negate()).omitEmptyStrings();
    	
    	Map<String, Integer> wordFreq = new HashMap<String, Integer>();
    	
    	for(String word : wordSplitter.split(context)){
    		Integer curFreq = wordFreq.get(word);
    		if(curFreq==null){
    			curFreq = 0;
    		}
    		wordFreq.put(word, ++curFreq);
    	}
    	
    	return wordFreq;
    }
}
